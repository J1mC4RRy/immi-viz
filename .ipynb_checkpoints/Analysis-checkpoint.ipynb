{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f4c40625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved at: C:\\Visual Studio Code Programs\\Personal projects\\Streamlit projects\\Immigration Australia\\output.xlsx\n",
      "Modified output file saved at: C:\\Visual Studio Code Programs\\Personal projects\\Streamlit projects\\Immigration Australia\\output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# First, define the file path for the initial Excel file\n",
    "pwd = os.getcwd()\n",
    "\n",
    "initial_file_path = os.path.join(os.getcwd(), \"34070DO001_202122.xlsx\")\n",
    "\n",
    "# Load the initial Excel file\n",
    "initial_xls = pd.ExcelFile(initial_file_path)\n",
    "\n",
    "# Get a list of sheet names from the initial Excel file excluding 'Contents'\n",
    "initial_sheet_names = [sheet_name for sheet_name in initial_xls.sheet_names if sheet_name != 'Contents']\n",
    "\n",
    "# Define a dictionary to map the original sheet names to the desired names\n",
    "rename_mapping = {\n",
    "    'Table 1.1': 'Australia',\n",
    "    'Table 1.2': 'New South Wales',\n",
    "    'Table 1.3': 'Victoria',\n",
    "    'Table 1.4': 'Queensland',\n",
    "    'Table 1.5': 'South Australia',\n",
    "    'Table 1.6': 'Western Australia',\n",
    "    'Table 1.7': 'Tasmania',\n",
    "    'Table 1.8': 'Northern Territory',\n",
    "    'Table 1.9': 'ACT'\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the dataframes for each sheet from the initial Excel file\n",
    "initial_dfs = {}\n",
    "\n",
    "# Loop through each sheet in the initial Excel file and read the data\n",
    "for sheet_name in initial_sheet_names:\n",
    "    # Define skip rows based on the sheet name\n",
    "    if sheet_name == 'Table 1.1':\n",
    "        skip_rows = 12\n",
    "    else:\n",
    "        skip_rows = 11\n",
    "\n",
    "    # Read the sheet into a dataframe from the initial Excel file, skipping rows as needed\n",
    "    initial_df = pd.read_excel(initial_xls, sheet_name=sheet_name, skiprows=skip_rows)\n",
    "    \n",
    "    # Store the dataframe in the dictionary\n",
    "    initial_dfs[sheet_name] = initial_df\n",
    "\n",
    "# Define the file path for the output Excel file\n",
    "output_file_path = os.path.join(os.getcwd(), \"output.xlsx\")\n",
    "\n",
    "# Create a Pandas Excel writer for the output Excel file\n",
    "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as output_writer:\n",
    "    # Write each dataframe from the initial Excel file to a separate sheet with the renamed names\n",
    "    for sheet_name, df in initial_dfs.items():\n",
    "        # Use the rename mapping to get the desired sheet name\n",
    "        new_sheet_name = rename_mapping.get(sheet_name, sheet_name)\n",
    "        \n",
    "        # Drop rows after row 250\n",
    "        df = df.iloc[:250]\n",
    "        \n",
    "        df.to_excel(output_writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Output file saved at: {output_file_path}\")\n",
    "\n",
    "# Now, define the file path for the input Excel file (output file from the previous step)\n",
    "input_file_path = os.path.join(os.getcwd(), \"output.xlsx\")\n",
    "\n",
    "# Load the input Excel file\n",
    "input_xls = pd.ExcelFile(input_file_path)\n",
    "\n",
    "# Get a list of sheet names from the input Excel file\n",
    "input_sheet_names = input_xls.sheet_names\n",
    "\n",
    "# Create a dictionary to store the dataframes for each sheet from the input Excel file\n",
    "input_dfs = {}\n",
    "\n",
    "# Loop through each sheet in the input Excel file, read the data, and skip the first row\n",
    "for sheet_name in input_sheet_names:\n",
    "    input_df = pd.read_excel(input_xls, sheet_name=sheet_name, header=1)  # Skip the first row and use the second row as the header\n",
    "    input_dfs[sheet_name] = input_df\n",
    "\n",
    "# Overwrite the input Excel file with the modified data\n",
    "with pd.ExcelWriter(input_file_path, engine='xlsxwriter') as input_writer:\n",
    "    # Write each dataframe to a separate sheet\n",
    "    for sheet_name, df in input_dfs.items():\n",
    "        df.to_excel(input_writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Modified output file saved at: {input_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3be28a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melted data saved at: C:\\Visual Studio Code Programs\\Personal projects\\Streamlit projects\\Immigration Australia\\melted_output.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shivak\\AppData\\Local\\Temp\\ipykernel_24052\\3131321139.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Year'] = df['Year'].str.replace(r'\\(d\\)', '').str.strip()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   SACC code(c) Country of birth(c)     Year  Count of Migrants  \\\n",
       " 0          1101           Australia  2004-05              -7430   \n",
       " 1          1102      Norfolk Island  2004-05                  0   \n",
       " 2          1199       Aust E T, nec  2004-05                  0   \n",
       " 3          1201         New Zealand  2004-05               4080   \n",
       " 4          1301       New Caledonia  2004-05                 10   \n",
       " \n",
       "              State  \n",
       " 0  New South Wales  \n",
       " 1  New South Wales  \n",
       " 2  New South Wales  \n",
       " 3  New South Wales  \n",
       " 4  New South Wales  ,\n",
       " 'C:\\\\Visual Studio Code Programs\\\\Personal projects\\\\Streamlit projects\\\\Immigration Australia\\\\melted_output.xlsx')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def melt_dataframe(xls, sheet_name):\n",
    "    \"\"\"Melt a specific sheet from the Excel file.\"\"\"\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    melted_df = (df.melt(id_vars=df.columns[:2], value_vars=df.columns[2:], \n",
    "                         var_name='Year', value_name='Count of Migrants')\n",
    "                 .assign(State=sheet_name))\n",
    "    return melted_df\n",
    "\n",
    "\n",
    "def melt_and_save_to_xlsx(file_path, output_path):\n",
    "    \"\"\"Melt all sheets (except 'Australia') from the Excel file and save to another file.\"\"\"\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    melted_dfs = [melt_dataframe(xls, sheet_name) for sheet_name in xls.sheet_names if sheet_name != 'Australia']\n",
    "    combined_df = pd.concat(melted_dfs, ignore_index=True)\n",
    "\n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "        combined_df.to_excel(writer, sheet_name=\"Melted Data\", index=False)\n",
    "\n",
    "    print(f\"Melted data saved at: {output_path}\")\n",
    "\n",
    "\n",
    "def clean_and_save_df(file_path, output_path):\n",
    "    \"\"\"Load the dataframe, clean the 'Year' column, and save it back.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df['Year'] = df['Year'].str.replace(r'\\(d\\)', '').str.strip()\n",
    "    df.to_excel(output_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Usage\n",
    "input_path = os.path.join(os.getcwd(), \"output.xlsx\")\n",
    "melted_path = os.path.join(os.getcwd(), \"melted_output.xlsx\")\n",
    "\n",
    "melt_and_save_to_xlsx(input_path, melted_path)\n",
    "df = clean_and_save_df(melted_path, melted_path)\n",
    "df.head(), melted_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e974208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melted data saved at: C:\\Visual Studio Code Programs\\Personal projects\\Streamlit projects\\Immigration Australia\\melted_output.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shivak\\AppData\\Local\\Temp\\ipykernel_24052\\1417134541.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Year'] = df['Year'].str.replace(r'\\(d\\)', '').str.strip()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80162f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252b205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
